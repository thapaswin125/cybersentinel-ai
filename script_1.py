# Create OSINT Intelligence Collector Module
osint_collector = '''"""
CyberSentinel AI - OSINT Intelligence Collector
Automated Open Source Intelligence gathering and analysis
"""

import requests
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import json
import hashlib
from datetime import datetime, timedelta
import logging
import re
from urllib.parse import urljoin, urlparse
import time

class OSINTCollector:
    """
    Advanced OSINT collection engine for automated threat intelligence gathering
    """
    
    def __init__(self, config_path=None):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        self.threat_intel_feeds = [
            'https://feodotracker.abuse.ch/downloads/ipblocklist.txt',
            'https://sslbl.abuse.ch/blacklist/sslipblacklist.txt',
            'https://urlhaus.abuse.ch/downloads/text/',
        ]
        
        self.social_media_endpoints = {
            'twitter': 'https://api.twitter.com/2/tweets/search/recent',
            'reddit': 'https://www.reddit.com/r/cybersecurity/search.json'
        }
        
        # Configure logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # Threat keywords for monitoring
        self.threat_keywords = [
            'apt', 'malware', 'ransomware', 'phishing', 'data breach',
            'vulnerability', 'exploit', 'botnet', 'ddos', 'cyber attack'
        ]
        
    def collect_threat_feeds(self):
        """
        Collect indicators from public threat intelligence feeds
        """
        collected_indicators = []
        
        try:
            for feed_url in self.threat_intel_feeds:
                self.logger.info(f"Collecting from feed: {feed_url}")
                
                try:
                    response = self.session.get(feed_url, timeout=30)
                    if response.status_code == 200:
                        indicators = self.parse_feed_content(response.text, feed_url)
                        collected_indicators.extend(indicators)
                        
                except Exception as e:
                    self.logger.error(f"Error collecting from {feed_url}: {e}")
                    
                # Rate limiting
                time.sleep(2)
                
        except Exception as e:
            self.logger.error(f"Error in threat feed collection: {e}")
            
        return collected_indicators
    
    def parse_feed_content(self, content, source_url):
        """
        Parse threat intelligence feed content
        """
        indicators = []
        
        try:
            lines = content.strip().split('\\n')
            
            for line in lines:
                line = line.strip()
                
                # Skip comments and empty lines
                if line.startswith('#') or not line:
                    continue
                    
                # Detect indicator type
                indicator_type = self.detect_indicator_type(line)
                
                if indicator_type:
                    indicator = {
                        'value': line,
                        'type': indicator_type,
                        'source': source_url,
                        'collected_at': datetime.now().isoformat(),
                        'confidence': self.calculate_feed_confidence(source_url),
                        'tags': self.extract_tags_from_source(source_url)
                    }
                    indicators.append(indicator)
                    
        except Exception as e:
            self.logger.error(f"Error parsing feed content: {e}")
            
        return indicators
    
    def detect_indicator_type(self, indicator):
        """
        Detect the type of indicator (IP, domain, URL, hash, etc.)
        """
        # IP address pattern
        ip_pattern = r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$'
        
        # Domain pattern
        domain_pattern = r'^[a-zA-Z0-9][a-zA-Z0-9-]{0,61}[a-zA-Z0-9]?\\.[a-zA-Z]{2,}$'
        
        # URL pattern
        url_pattern = r'^https?://.*'
        
        # Hash patterns
        md5_pattern = r'^[a-fA-F0-9]{32}$'
        sha1_pattern = r'^[a-fA-F0-9]{40}$'
        sha256_pattern = r'^[a-fA-F0-9]{64}$'
        
        if re.match(ip_pattern, indicator):
            return 'ip'
        elif re.match(url_pattern, indicator):
            return 'url'
        elif re.match(domain_pattern, indicator):
            return 'domain'
        elif re.match(sha256_pattern, indicator):
            return 'sha256'
        elif re.match(sha1_pattern, indicator):
            return 'sha1'
        elif re.match(md5_pattern, indicator):
            return 'md5'
        
        return None
    
    def calculate_feed_confidence(self, source_url):
        """
        Calculate confidence score based on source reputation
        """
        trusted_sources = {
            'abuse.ch': 0.9,
            'virustotal.com': 0.85,
            'malwaredomainlist.com': 0.8,
            'phishtank.com': 0.8
        }
        
        for source, confidence in trusted_sources.items():
            if source in source_url:
                return confidence
                
        return 0.5  # Default confidence for unknown sources
    
    def extract_tags_from_source(self, source_url):
        """
        Extract relevant tags based on source URL
        """
        tags = []
        
        if 'feodo' in source_url:
            tags.extend(['botnet', 'banking-trojan'])
        elif 'sslbl' in source_url:
            tags.extend(['malware', 'c2-communication'])
        elif 'urlhaus' in source_url:
            tags.extend(['malware-hosting', 'payload-delivery'])
            
        return tags
    
    async def monitor_social_media(self, keywords=None):
        """
        Monitor social media platforms for threat-related discussions
        """
        if keywords is None:
            keywords = self.threat_keywords
            
        social_indicators = []
        
        try:
            # Monitor Reddit cybersecurity discussions
            reddit_data = await self.collect_reddit_intelligence(keywords)
            social_indicators.extend(reddit_data)
            
            # Note: Twitter API requires authentication
            # twitter_data = await self.collect_twitter_intelligence(keywords)
            # social_indicators.extend(twitter_data)
            
        except Exception as e:
            self.logger.error(f"Error monitoring social media: {e}")
            
        return social_indicators
    
    async def collect_reddit_intelligence(self, keywords):
        """
        Collect threat intelligence from Reddit cybersecurity communities
        """
        indicators = []
        
        try:
            async with aiohttp.ClientSession() as session:
                for keyword in keywords:
                    url = f"https://www.reddit.com/r/cybersecurity/search.json?q={keyword}&sort=new&limit=25"
                    
                    try:
                        async with session.get(url) as response:
                            if response.status == 200:
                                data = await response.json()
                                posts = data.get('data', {}).get('children', [])
                                
                                for post in posts:
                                    post_data = post.get('data', {})
                                    
                                    # Extract IOCs from post content
                                    iocs = self.extract_iocs_from_text(
                                        post_data.get('title', '') + ' ' + 
                                        post_data.get('selftext', '')
                                    )
                                    
                                    for ioc in iocs:
                                        indicator = {
                                            'value': ioc['value'],
                                            'type': ioc['type'],
                                            'source': 'Reddit r/cybersecurity',
                                            'source_url': f"https://reddit.com{post_data.get('permalink', '')}",
                                            'collected_at': datetime.now().isoformat(),
                                            'confidence': 0.6,  # Medium confidence for social media
                                            'context': post_data.get('title', ''),
                                            'tags': ['social-media', 'community-report', keyword]
                                        }
                                        indicators.append(indicator)
                                        
                    except Exception as e:
                        self.logger.error(f"Error collecting Reddit data for {keyword}: {e}")
                    
                    # Rate limiting
                    await asyncio.sleep(2)
                    
        except Exception as e:
            self.logger.error(f"Error in Reddit intelligence collection: {e}")
            
        return indicators
    
    def extract_iocs_from_text(self, text):
        """
        Extract Indicators of Compromise from text content
        """
        iocs = []
        
        # IP address pattern
        ip_pattern = r'\\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\b'
        
        # Domain pattern
        domain_pattern = r'\\b[a-zA-Z0-9][a-zA-Z0-9-]{0,61}[a-zA-Z0-9]?\\.[a-zA-Z]{2,}\\b'
        
        # URL pattern
        url_pattern = r'https?://[^\\s<>"{}|\\\\^`\\[\\]]+'
        
        # Hash patterns
        hash_patterns = {
            'md5': r'\\b[a-fA-F0-9]{32}\\b',
            'sha1': r'\\b[a-fA-F0-9]{40}\\b',
            'sha256': r'\\b[a-fA-F0-9]{64}\\b'
        }
        
        # Extract IPs
        ips = re.findall(ip_pattern, text)
        for ip in ips:
            iocs.append({'value': ip, 'type': 'ip'})
            
        # Extract URLs
        urls = re.findall(url_pattern, text)
        for url in urls:
            iocs.append({'value': url, 'type': 'url'})
            
        # Extract domains (excluding IPs and URLs)
        domains = re.findall(domain_pattern, text)
        for domain in domains:
            if not re.match(ip_pattern, domain) and not any(url.startswith('http') for url in urls if domain in url):
                iocs.append({'value': domain, 'type': 'domain'})
                
        # Extract hashes
        for hash_type, pattern in hash_patterns.items():
            hashes = re.findall(pattern, text)
            for hash_val in hashes:
                iocs.append({'value': hash_val, 'type': hash_type})
                
        return iocs
    
    def enrich_indicators(self, indicators):
        """
        Enrich collected indicators with additional context
        """
        enriched_indicators = []
        
        for indicator in indicators:
            try:
                enriched = indicator.copy()
                
                # Add geolocation for IP addresses
                if indicator['type'] == 'ip':
                    geo_info = self.get_ip_geolocation(indicator['value'])
                    enriched['geolocation'] = geo_info
                    
                # Add reputation scores
                enriched['reputation_score'] = self.calculate_reputation_score(indicator)
                
                # Add threat categories
                enriched['threat_categories'] = self.categorize_threat(indicator)
                
                enriched_indicators.append(enriched)
                
            except Exception as e:
                self.logger.error(f"Error enriching indicator {indicator['value']}: {e}")
                enriched_indicators.append(indicator)
                
        return enriched_indicators
    
    def get_ip_geolocation(self, ip_address):
        """
        Get geolocation information for IP address (mock implementation)
        """
        # In a real implementation, you would use a geolocation API
        mock_geo = {
            'country': 'Unknown',
            'city': 'Unknown',
            'latitude': 0.0,
            'longitude': 0.0,
            'asn': 'Unknown'
        }
        
        return mock_geo
    
    def calculate_reputation_score(self, indicator):
        """
        Calculate reputation score for indicator
        """
        base_score = 0.5
        
        # Adjust based on source confidence
        source_confidence = indicator.get('confidence', 0.5)
        
        # Adjust based on tags
        threat_tags = ['malware', 'botnet', 'phishing', 'c2-communication']
        tag_score = sum(0.1 for tag in indicator.get('tags', []) if tag in threat_tags)
        
        reputation_score = min(1.0, base_score + source_confidence + tag_score)
        return reputation_score
    
    def categorize_threat(self, indicator):
        """
        Categorize threat based on indicator characteristics
        """
        categories = []
        
        tags = indicator.get('tags', [])
        source = indicator.get('source', '').lower()
        
        if any(tag in ['malware', 'trojan', 'virus'] for tag in tags):
            categories.append('Malware')
        if any(tag in ['botnet', 'c2-communication'] for tag in tags):
            categories.append('Botnet')
        if any(tag in ['phishing', 'credential-harvesting'] for tag in tags):
            categories.append('Phishing')
        if 'ddos' in source or 'ddos' in tags:
            categories.append('DDoS')
            
        return categories if categories else ['Unknown']
    
    def generate_report(self, indicators):
        """
        Generate OSINT intelligence report
        """
        report = {
            'generated_at': datetime.now().isoformat(),
            'total_indicators': len(indicators),
            'indicator_types': {},
            'threat_categories': {},
            'top_sources': {},
            'indicators': indicators[:100]  # Limit to first 100 for report
        }
        
        # Count indicator types
        for indicator in indicators:
            ioc_type = indicator.get('type', 'unknown')
            report['indicator_types'][ioc_type] = report['indicator_types'].get(ioc_type, 0) + 1
            
        # Count threat categories
        for indicator in indicators:
            categories = indicator.get('threat_categories', ['Unknown'])
            for category in categories:
                report['threat_categories'][category] = report['threat_categories'].get(category, 0) + 1
                
        # Count top sources
        for indicator in indicators:
            source = indicator.get('source', 'Unknown')
            report['top_sources'][source] = report['top_sources'].get(source, 0) + 1
            
        return report

# Example usage
if __name__ == "__main__":
    async def main():
        collector = OSINTCollector()
        
        print("=== CyberSentinel AI OSINT Collection ===\\n")
        
        # Collect from threat intelligence feeds
        print("Collecting from threat intelligence feeds...")
        feed_indicators = collector.collect_threat_feeds()
        print(f"Collected {len(feed_indicators)} indicators from feeds")
        
        # Monitor social media (limited example)
        print("\\nMonitoring social media...")
        social_indicators = await collector.monitor_social_media(['malware', 'phishing'])
        print(f"Collected {len(social_indicators)} indicators from social media")
        
        # Combine all indicators
        all_indicators = feed_indicators + social_indicators
        
        # Enrich indicators
        print("\\nEnriching indicators...")
        enriched_indicators = collector.enrich_indicators(all_indicators)
        
        # Generate report
        report = collector.generate_report(enriched_indicators)
        
        print("\\n=== OSINT Intelligence Report ===")
        print(f"Total Indicators: {report['total_indicators']}")
        print(f"Indicator Types: {report['indicator_types']}")
        print(f"Threat Categories: {report['threat_categories']}")
        print(f"Top Sources: {list(report['top_sources'].keys())[:5]}")
        
        # Save report
        with open('osint_report.json', 'w') as f:
            json.dump(report, f, indent=2)
            
        print("\\nReport saved to osint_report.json")
    
    # Run the async main function
    asyncio.run(main())
'''

# Save OSINT collector module
with open('osint_collector.py', 'w') as f:
    f.write(osint_collector)

print("âœ… Created osint_collector.py")

# Create SOAR automation engine module
soar_engine = '''"""
CyberSentinel AI - SOAR Automation Engine
Security Orchestration, Automation and Response system
"""

import json
import asyncio
from datetime import datetime, timedelta
from enum import Enum
from dataclasses import dataclass, asdict
from typing import Dict, List, Any, Optional
import logging
import uuid

class IncidentSeverity(Enum):
    LOW = "Low"
    MEDIUM = "Medium"
    HIGH = "High"
    CRITICAL = "Critical"

class PlaybookStatus(Enum):
    IDLE = "Idle"
    RUNNING = "Running"
    SUCCESS = "Success"
    FAILED = "Failed"
    PAUSED = "Paused"

class ActionResult(Enum):
    SUCCESS = "Success"
    FAILED = "Failed"
    TIMEOUT = "Timeout"
    PENDING = "Pending"

@dataclass
class SecurityIncident:
    """Security incident data structure"""
    id: str
    title: str
    description: str
    severity: IncidentSeverity
    source_ip: str = ""
    target_ip: str = ""
    attack_type: str = ""
    created_at: str = ""
    updated_at: str = ""
    status: str = "Open"
    assigned_playbook: str = ""
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        if not self.updated_at:
            self.updated_at = self.created_at

@dataclass
class PlaybookAction:
    """Individual action within a playbook"""
    id: str
    name: str
    action_type: str
    parameters: Dict[str, Any]
    timeout: int = 60
    retry_count: int = 0
    max_retries: int = 3
    depends_on: List[str] = None
    
    def __post_init__(self):
        if self.depends_on is None:
            self.depends_on = []

class SOAREngine:
    """
    Security Orchestration, Automation and Response Engine
    """
    
    def __init__(self):
        self.incidents: Dict[str, SecurityIncident] = {}
        self.playbooks: Dict[str, Dict] = {}
        self.active_executions: Dict[str, Dict] = {}
        
        # Configure logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # Initialize default playbooks
        self.initialize_default_playbooks()
        
        # Integration endpoints (mock)
        self.integrations = {
            'firewall': {'endpoint': 'https://firewall.api/v1/', 'auth': 'api_key'},
            'siem': {'endpoint': 'https://siem.api/v1/', 'auth': 'bearer_token'},
            'edr': {'endpoint': 'https://edr.api/v1/', 'auth': 'api_key'},
            'email_gateway': {'endpoint': 'https://email.api/v1/', 'auth': 'oauth2'}
        }
    
    def initialize_default_playbooks(self):
        """Initialize default incident response playbooks"""
        
        # DDoS Response Playbook
        ddos_playbook = {
            'id': 'ddos_response',
            'name': 'DDoS Attack Response',
            'description': 'Automated response to DDoS attacks',
            'trigger_conditions': ['attack_type:ddos', 'severity:high,critical'],
            'actions': [
                PlaybookAction(
                    id='block_source_ip',
                    name='Block Source IP at Firewall',
                    action_type='firewall_block',
                    parameters={'ip_list': '{{incident.source_ip}}', 'rule_name': 'DDoS_Block_{{incident.id}}'}
                ),
                PlaybookAction(
                    id='rate_limit_enable',
                    name='Enable Rate Limiting',
                    action_type='rate_limit',
                    parameters={'target': '{{incident.target_ip}}', 'limit': 100},
                    depends_on=['block_source_ip']
                ),
                PlaybookAction(
                    id='notify_soc',
                    name='Notify SOC Team',
                    action_type='notification',
                    parameters={'channel': 'slack', 'message': 'DDoS attack detected and blocked'},
                    depends_on=['rate_limit_enable']
                )
            ]
        }
        
        # Malware Response Playbook
        malware_playbook = {
            'id': 'malware_containment',
            'name': 'Malware Containment and Analysis',
            'description': 'Automated malware containment and forensic analysis',
            'trigger_conditions': ['attack_type:malware', 'severity:medium,high,critical'],
            'actions': [
                PlaybookAction(
                    id='isolate_host',
                    name='Isolate Infected Host',
                    action_type='edr_isolate',
                    parameters={'host_ip': '{{incident.source_ip}}', 'isolation_type': 'network'}
                ),
                PlaybookAction(
                    id='collect_forensics',
                    name='Collect Forensic Data',
                    action_type='forensics_collection',
                    parameters={'host_ip': '{{incident.source_ip}}', 'data_types': ['memory', 'disk', 'network']},
                    depends_on=['isolate_host']
                ),
                PlaybookAction(
                    id='malware_analysis',
                    name='Submit to Malware Analysis',
                    action_type='malware_analysis',
                    parameters={'sample_source': 'forensics_data'},
                    depends_on=['collect_forensics']
                ),
                PlaybookAction(
                    id='update_iocs',
                    name='Update IOC Database',
                    action_type='ioc_update',
                    parameters={'source': 'malware_analysis_results'},
                    depends_on=['malware_analysis']
                )
            ]
        }
        
        # Phishing Response Playbook
        phishing_playbook = {
            'id': 'phishing_response',
            'name': 'Phishing Email Response',
            'description': 'Automated phishing email detection and remediation',
            'trigger_conditions': ['attack_type:phishing', 'severity:low,medium,high'],
            'actions': [
                PlaybookAction(
                    id='block_sender_domain',
                    name='Block Sender Domain',
                    action_type='email_block',
                    parameters={'domain': '{{incident.sender_domain}}', 'block_type': 'sender'}
                ),
                PlaybookAction(
                    id='quarantine_emails',
                    name='Quarantine Similar Emails',
                    action_type='email_quarantine',
                    parameters={'search_criteria': 'sender:{{incident.sender_domain}}'},
                    depends_on=['block_sender_domain']
                ),
                PlaybookAction(
                    id='user_notification',
                    name='Notify Affected Users',
                    action_type='user_notification',
                    parameters={'recipients': '{{incident.target_users}}', 'template': 'phishing_warning'},
                    depends_on=['quarantine_emails']
                )
            ]
        }
        
        self.playbooks = {
            'ddos_response': ddos_playbook,
            'malware_containment': malware_playbook,
            'phishing_response': phishing_playbook
        }
    
    def create_incident(self, incident_data: Dict[str, Any]) -> SecurityIncident:
        """Create a new security incident"""
        
        incident_id = f"INC-{str(uuid.uuid4())[:8]}"
        
        incident = SecurityIncident(
            id=incident_id,
            title=incident_data.get('title', 'Unknown Incident'),
            description=incident_data.get('description', ''),
            severity=IncidentSeverity(incident_data.get('severity', 'Medium')),
            source_ip=incident_data.get('source_ip', ''),
            target_ip=incident_data.get('target_ip', ''),
            attack_type=incident_data.get('attack_type', 'unknown')
        )
        
        self.incidents[incident_id] = incident
        self.logger.info(f"Created incident {incident_id}: {incident.title}")
        
        # Auto-assign playbook based on attack type and severity
        assigned_playbook = self.select_playbook(incident)
        if assigned_playbook:
            incident.assigned_playbook = assigned_playbook
            self.logger.info(f"Assigned playbook {assigned_playbook} to incident {incident_id}")
            
        return incident
    
    def select_playbook(self, incident: SecurityIncident) -> Optional[str]:
        """Select appropriate playbook based on incident characteristics"""
        
        attack_type = incident.attack_type.lower()
        severity = incident.severity.value.lower()
        
        # Simple playbook selection logic
        if 'ddos' in attack_type and severity in ['high', 'critical']:
            return 'ddos_response'
        elif 'malware' in attack_type and severity in ['medium', 'high', 'critical']:
            return 'malware_containment'
        elif 'phishing' in attack_type:
            return 'phishing_response'
            
        return None
    
    async def execute_playbook(self, incident_id: str, playbook_id: str = None) -> Dict[str, Any]:
        """Execute a playbook for a given incident"""
        
        if incident_id not in self.incidents:
            raise ValueError(f"Incident {incident_id} not found")
            
        incident = self.incidents[incident_id]
        
        if not playbook_id:
            playbook_id = incident.assigned_playbook
            
        if not playbook_id or playbook_id not in self.playbooks:
            raise ValueError(f"Playbook {playbook_id} not found")
            
        playbook = self.playbooks[playbook_id]
        execution_id = f"exec-{str(uuid.uuid4())[:8]}"
        
        execution_context = {
            'execution_id': execution_id,
            'incident_id': incident_id,
            'playbook_id': playbook_id,
            'status': PlaybookStatus.RUNNING,
            'started_at': datetime.now().isoformat(),
            'actions_completed': [],
            'actions_failed': [],
            'current_action': None,
            'variables': {'incident': asdict(incident)}
        }
        
        self.active_executions[execution_id] = execution_context
        self.logger.info(f"Started playbook execution {execution_id} for incident {incident_id}")
        
        try:
            # Execute playbook actions
            for action in playbook['actions']:
                # Check dependencies
                if not self.check_action_dependencies(action, execution_context):
                    self.logger.warning(f"Dependencies not met for action {action.id}")
                    continue
                    
                execution_context['current_action'] = action.id
                self.logger.info(f"Executing action: {action.name}")
                
                # Execute the action
                result = await self.execute_action(action, execution_context)
                
                if result == ActionResult.SUCCESS:
                    execution_context['actions_completed'].append(action.id)
                    self.logger.info(f"Action {action.name} completed successfully")
                else:
                    execution_context['actions_failed'].append(action.id)
                    self.logger.error(f"Action {action.name} failed")
                    
            # Determine final status
            if execution_context['actions_failed']:
                execution_context['status'] = PlaybookStatus.FAILED
            else:
                execution_context['status'] = PlaybookStatus.SUCCESS
                
        except Exception as e:
            self.logger.error(f"Playbook execution failed: {e}")
            execution_context['status'] = PlaybookStatus.FAILED
            
        finally:
            execution_context['completed_at'] = datetime.now().isoformat()
            execution_context['current_action'] = None
            
        return execution_context
    
    def check_action_dependencies(self, action: PlaybookAction, execution_context: Dict) -> bool:
        """Check if action dependencies are satisfied"""
        
        if not action.depends_on:
            return True
            
        completed_actions = execution_context.get('actions_completed', [])
        return all(dep in completed_actions for dep in action.depends_on)
    
    async def execute_action(self, action: PlaybookAction, context: Dict) -> ActionResult:
        """Execute a single playbook action"""
        
        try:
            # Simulate action execution based on type
            if action.action_type == 'firewall_block':
                return await self.execute_firewall_block(action, context)
            elif action.action_type == 'edr_isolate':
                return await self.execute_edr_isolate(action, context)
            elif action.action_type == 'email_block':
                return await self.execute_email_block(action, context)
            elif action.action_type == 'notification':
                return await self.execute_notification(action, context)
            else:
                # Generic action execution
                return await self.execute_generic_action(action, context)
                
        except Exception as e:
            self.logger.error(f"Action execution failed: {e}")
            return ActionResult.FAILED
    
    async def execute_firewall_block(self, action: PlaybookAction, context: Dict) -> ActionResult:
        """Execute firewall blocking action"""
        
        self.logger.info("Executing firewall block action...")
        
        # Simulate API call to firewall
        await asyncio.sleep(2)  # Simulate network delay
        
        # Mock successful execution
        ip_to_block = action.parameters.get('ip_list', '')
        self.logger.info(f"Blocked IP {ip_to_block} at firewall")
        
        return ActionResult.SUCCESS
    
    async def execute_edr_isolate(self, action: PlaybookAction, context: Dict) -> ActionResult:
        """Execute EDR host isolation action"""
        
        self.logger.info("Executing EDR host isolation...")
        
        # Simulate API call to EDR system
        await asyncio.sleep(3)  # Simulate network delay
        
        host_ip = action.parameters.get('host_ip', '')
        self.logger.info(f"Isolated host {host_ip} from network")
        
        return ActionResult.SUCCESS
    
    async def execute_email_block(self, action: PlaybookAction, context: Dict) -> ActionResult:
        """Execute email blocking action"""
        
        self.logger.info("Executing email block action...")
        
        # Simulate API call to email gateway
        await asyncio.sleep(1.5)
        
        domain = action.parameters.get('domain', '')
        self.logger.info(f"Blocked email domain {domain}")
        
        return ActionResult.SUCCESS
    
    async def execute_notification(self, action: PlaybookAction, context: Dict) -> ActionResult:
        """Execute notification action"""
        
        self.logger.info("Sending notification...")
        
        # Simulate notification sending
        await asyncio.sleep(1)
        
        channel = action.parameters.get('channel', 'email')
        message = action.parameters.get('message', 'Security incident detected')
        self.logger.info(f"Sent notification via {channel}: {message}")
        
        return ActionResult.SUCCESS
    
    async def execute_generic_action(self, action: PlaybookAction, context: Dict) -> ActionResult:
        """Execute generic action"""
        
        self.logger.info(f"Executing generic action: {action.name}")
        
        # Simulate action execution
        await asyncio.sleep(2)
        
        # 90% success rate for simulation
        import random
        if random.random() > 0.1:
            return ActionResult.SUCCESS
        else:
            return ActionResult.FAILED
    
    def get_incident_status(self, incident_id: str) -> Dict[str, Any]:
        """Get current status of an incident"""
        
        if incident_id not in self.incidents:
            return {'error': 'Incident not found'}
            
        incident = self.incidents[incident_id]
        
        # Find related executions
        related_executions = [
            exec_data for exec_data in self.active_executions.values()
            if exec_data['incident_id'] == incident_id
        ]
        
        return {
            'incident': asdict(incident),
            'executions': related_executions
        }
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get SOAR engine performance metrics"""
        
        total_incidents = len(self.incidents)
        total_executions = len(self.active_executions)
        
        # Calculate success rates
        successful_executions = sum(
            1 for exec_data in self.active_executions.values()
            if exec_data['status'] == PlaybookStatus.SUCCESS
        )
        
        success_rate = successful_executions / total_executions if total_executions > 0 else 0
        
        # Calculate average response time
        completed_executions = [
            exec_data for exec_data in self.active_executions.values()
            if 'completed_at' in exec_data
        ]
        
        avg_response_time = 0
        if completed_executions:
            total_time = 0
            for exec_data in completed_executions:
                start_time = datetime.fromisoformat(exec_data['started_at'])
                end_time = datetime.fromisoformat(exec_data['completed_at'])
                total_time += (end_time - start_time).total_seconds()
            avg_response_time = total_time / len(completed_executions)
        
        return {
            'total_incidents': total_incidents,
            'total_executions': total_executions,
            'successful_executions': successful_executions,
            'success_rate': round(success_rate * 100, 2),
            'average_response_time': round(avg_response_time, 2),
            'active_playbooks': len(self.playbooks)
        }

# Example usage
if __name__ == "__main__":
    async def main():
        soar = SOAREngine()
        
        print("=== CyberSentinel AI SOAR Engine ===\\n")
        
        # Create sample incidents
        ddos_incident = soar.create_incident({
            'title': 'DDoS Attack Detected',
            'description': 'High volume traffic from multiple sources',
            'severity': 'High',
            'source_ip': '185.220.101.42',
            'target_ip': '192.168.1.100',
            'attack_type': 'ddos'
        })
        
        malware_incident = soar.create_incident({
            'title': 'Malware Communication Detected',
            'description': 'Suspicious outbound connection to known C2 server',
            'severity': 'Critical',
            'source_ip': '192.168.1.105',
            'target_ip': 'external-c2.malware.net',
            'attack_type': 'malware'
        })
        
        print(f"Created incidents: {ddos_incident.id}, {malware_incident.id}")
        
        # Execute playbooks
        print("\\nExecuting playbooks...")
        
        ddos_execution = await soar.execute_playbook(ddos_incident.id)
        malware_execution = await soar.execute_playbook(malware_incident.id)
        
        print(f"DDoS playbook execution: {ddos_execution['status'].value}")
        print(f"Malware playbook execution: {malware_execution['status'].value}")
        
        # Show metrics
        metrics = soar.get_metrics()
        print("\\n=== SOAR Engine Metrics ===")
        print(f"Total Incidents: {metrics['total_incidents']}")
        print(f"Total Executions: {metrics['total_executions']}")
        print(f"Success Rate: {metrics['success_rate']}%")
        print(f"Average Response Time: {metrics['average_response_time']} seconds")
    
    # Run the async main function
    asyncio.run(main())
'''

# Save SOAR engine module
with open('soar_engine.py', 'w') as f:
    f.write(soar_engine)

print("âœ… Created soar_engine.py")

# Create Docker configuration
dockerfile_content = '''# CyberSentinel AI Dockerfile
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    libpq-dev \\
    curl \\
    git \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements file
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create necessary directories
RUN mkdir -p /app/logs /app/data /app/models

# Set environment variables
ENV PYTHONPATH=/app
ENV FLASK_APP=app.py
ENV FLASK_ENV=production

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run the application
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "--workers", "4", "--timeout", "120", "app:app"]
'''

with open('Dockerfile', 'w') as f:
    f.write(dockerfile_content)

print("âœ… Created Dockerfile")

# Create docker-compose configuration
docker_compose = '''version: '3.8'

services:
  cybersentinel-web:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/cybersentinel
      - REDIS_URL=redis://redis:6379/0
      - FLASK_ENV=production
    depends_on:
      - db
      - redis
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped

  cybersentinel-worker:
    build: .
    command: celery worker -A app.celery --loglevel=info
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/cybersentinel
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped

  cybersentinel-scheduler:
    build: .
    command: celery beat -A app.celery --loglevel=info
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/cybersentinel
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    volumes:
      - ./data:/app/data
    restart: unless-stopped

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=cybersentinel
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    restart: unless-stopped

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    restart: unless-stopped

  misp:
    image: coolacid/misp-docker:core-latest
    environment:
      - MYSQL_HOST=misp-db
      - MYSQL_DATABASE=misp
      - MYSQL_USER=misp
      - MYSQL_PASSWORD=misp_password
      - MISP_ADMIN_EMAIL=admin@cybersentinel.ai
      - MISP_ADMIN_PASSPHRASE=admin_password
    ports:
      - "8080:80"
    depends_on:
      - misp-db
    volumes:
      - misp_data:/var/www/MISP
    restart: unless-stopped

  misp-db:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=root_password
      - MYSQL_DATABASE=misp
      - MYSQL_USER=misp
      - MYSQL_PASSWORD=misp_password
    volumes:
      - misp_db_data:/var/lib/mysql
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  es_data:
  misp_data:
  misp_db_data:
  prometheus_data:
  grafana_data:
'''

with open('docker-compose.yml', 'w') as f:
    f.write(docker_compose)

print("âœ… Created docker-compose.yml")
print("\nðŸŽ‰ Complete CyberSentinel AI project created successfully!")
print("\nProject includes:")
print("- Web application (HTML/CSS/JavaScript)")
print("- AI Threat Detection module (Python)")
print("- OSINT Collection module (Python)")
print("- SOAR Automation engine (Python)")
print("- Complete requirements.txt")
print("- Docker configuration files")
print("- Comprehensive README documentation")